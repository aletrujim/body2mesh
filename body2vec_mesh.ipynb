{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvQm-A8ESKb2"
      },
      "source": [
        "### Files pending meshing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu1o4iqhAVY3",
        "outputId": "01702f19-8e7e-4c0c-88bd-f43b19538a32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpNYUoTKCu_O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def get_first_unprocessed_png(png_folder, review_folder):\n",
        "    png_files = [file for file in os.listdir(png_folder) if file.endswith('.png')]\n",
        "    png_names = [os.path.splitext(file)[0] for file in png_files]\n",
        "\n",
        "    # Check in the results folder if there are folders with the names of the .png files\n",
        "    names_to_remove = []\n",
        "    for name in png_names:\n",
        "        folder_path = os.path.join(review_folder, name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            names_to_remove.append(name)\n",
        "\n",
        "    # Remove the names that have corresponding folders from the list\n",
        "    final_names = [name for name in png_names if name not in names_to_remove]\n",
        "\n",
        "    #return f\"{final_names[0]}.png\" if final_names else None\n",
        "    first_unprocessed = f\"{final_names[0]}.png\" if final_names else None\n",
        "    return [first_unprocessed, len(png_files), len(png_files)-len(final_names)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9FSfxK9C5IN",
        "outputId": "3c746e78-505d-403e-b582-5af8d9d310f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first_unprocessed, total, done\n",
            "['B0029_rembg.png', 106, 31]\n"
          ]
        }
      ],
      "source": [
        "# Paths: files and results\n",
        "\n",
        "png_folder = ''\n",
        "review_folder = ''\n",
        "\n",
        "unprocessed_png = get_first_unprocessed_png(png_folder, review_folder)\n",
        "print(\"first_unprocessed, total, done\")\n",
        "print(unprocessed_png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh_cljH_A9PA"
      },
      "source": [
        "### Clone repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qddUM4vuA9fZ",
        "outputId": "2ea115d9-3d53-4074-9d5c-ad6b8380b629"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'body2vec_mesh'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 118 (delta 14), reused 112 (delta 12), pack-reused 3 (from 1)\u001b[K\n",
            "Receiving objects: 100% (118/118), 72.12 MiB | 13.21 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/aletrujim/body2vec_mesh.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjhEofNaAa9D"
      },
      "source": [
        "### Configure input / output data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUjZe0mC3196",
        "outputId": "d3632961-cdf9-4537-a185-167c56cb123b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "file_name  B0029_rembg.png\n"
          ]
        }
      ],
      "source": [
        "# input\n",
        "file_name = unprocessed_png[0] #first_unprocessed \".png\"\n",
        "print(\"file_name \", file_name)\n",
        "\n",
        "image_path_ori = \"/%s\" % file_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3icjzzW2E72"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# # input path\n",
        "shutil.copy(image_path_ori, \"\")\n",
        "image_path = '/%s' % file_name\n",
        "image_dir = os.path.dirname(image_path)\n",
        "\n",
        "# output paths\n",
        "obj_path = '/result_%s.obj' % file_name\n",
        "out_img_path = '/result_%s.png' % file_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbVmda9J5TDL"
      },
      "source": [
        "### Preprocess: human-pose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "896EC7iQfXkj"
      },
      "outputs": [],
      "source": [
        "from os import chdir as cd\n",
        "\n",
        "cd('/content/body2vec_mesh/human-pose')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdRcDXe38lHB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from models.with_mobilenet import PoseEstimationWithMobileNet\n",
        "from modules.keypoints import extract_keypoints, group_keypoints\n",
        "from modules.load_state import load_state\n",
        "from modules.pose import Pose, track_poses\n",
        "import demo\n",
        "\n",
        "#print(torch.__version__)\n",
        "\n",
        "def get_rect(net, images, height_size):\n",
        "    net = net.eval()\n",
        "\n",
        "    stride = 8\n",
        "    upsample_ratio = 4\n",
        "    num_keypoints = Pose.num_kpts\n",
        "    previous_poses = []\n",
        "    delay = 33\n",
        "    for image in images:\n",
        "        rect_path = image.replace('.%s' % (image.split('.')[-1]), '_rect.txt')\n",
        "        img = cv2.imread(image, cv2.IMREAD_COLOR)\n",
        "        orig_img = img.copy()\n",
        "        orig_img = img.copy()\n",
        "        heatmaps, pafs, scale, pad = demo.infer_fast(net, img, height_size, stride, upsample_ratio, cpu=False)\n",
        "\n",
        "        total_keypoints_num = 0\n",
        "        all_keypoints_by_type = []\n",
        "        for kpt_idx in range(num_keypoints):  # 19th for bg\n",
        "            total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n",
        "\n",
        "        pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n",
        "        for kpt_id in range(all_keypoints.shape[0]):\n",
        "            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n",
        "            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n",
        "        current_poses = []\n",
        "\n",
        "        rects = []\n",
        "        for n in range(len(pose_entries)):\n",
        "            if len(pose_entries[n]) == 0:\n",
        "                continue\n",
        "            pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n",
        "            valid_keypoints = []\n",
        "            for kpt_id in range(num_keypoints):\n",
        "                if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n",
        "                    pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n",
        "                    pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n",
        "                    valid_keypoints.append([pose_keypoints[kpt_id, 0], pose_keypoints[kpt_id, 1]])\n",
        "            valid_keypoints = np.array(valid_keypoints)\n",
        "\n",
        "            if pose_entries[n][10] != -1.0 or pose_entries[n][13] != -1.0:\n",
        "              pmin = valid_keypoints.min(0)\n",
        "              pmax = valid_keypoints.max(0)\n",
        "\n",
        "              center = (0.5 * (pmax[:2] + pmin[:2])).astype(np.int_)\n",
        "              radius = int(0.65 * max(pmax[0]-pmin[0], pmax[1]-pmin[1]))\n",
        "            elif pose_entries[n][10] == -1.0 and pose_entries[n][13] == -1.0 and pose_entries[n][8] != -1.0 and pose_entries[n][11] != -1.0:\n",
        "              # if leg is missing, use pelvis to get cropping\n",
        "              center = (0.5 * (pose_keypoints[8] + pose_keypoints[11])).astype(np.int_)\n",
        "              radius = int(1.45*np.sqrt(((center[None,:] - valid_keypoints)**2).sum(1)).max(0))\n",
        "              center[1] += int(0.05*radius)\n",
        "            else:\n",
        "              center = np.array([img.shape[1]//2,img.shape[0]//2])\n",
        "              radius = max(img.shape[1]//2,img.shape[0]//2)\n",
        "\n",
        "            x1 = center[0] - radius\n",
        "            y1 = center[1] - radius\n",
        "\n",
        "            rects.append([x1, y1, 2*radius, 2*radius])\n",
        "\n",
        "        np.savetxt(rect_path, np.array(rects), fmt='%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6cGZD6f6IaY"
      },
      "outputs": [],
      "source": [
        "net = PoseEstimationWithMobileNet()\n",
        "checkpoint = torch.load('/content/body2vec_mesh/checkpoint_iter_370000.pth', map_location='cpu')\n",
        "load_state(net, checkpoint)\n",
        "\n",
        "get_rect(net.cuda(), [image_path], 512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0rgMInwTt0s"
      },
      "source": [
        "### Pretrained Model: pifuhd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrIcZweSNRFI"
      },
      "outputs": [],
      "source": [
        "cd('/content/body2vec_mesh/pifuhd/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3jjm6HuQRk8",
        "outputId": "6926d19a-836a-44b8-a58d-01ea1ce80b52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+ mkdir -p checkpoints\n",
            "+ cd checkpoints\n",
            "+ wget https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt pifuhd.pt\n",
            "--2024-08-21 18:22:44--  https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.35.18.103, 13.35.18.102, 13.35.18.15, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.35.18.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1548375177 (1.4G) [application/octet-stream]\n",
            "Saving to: ‘pifuhd.pt’\n",
            "\n",
            "pifuhd.pt           100%[===================>]   1.44G   135MB/s    in 14s     \n",
            "\n",
            "2024-08-21 18:22:58 (109 MB/s) - ‘pifuhd.pt’ saved [1548375177/1548375177]\n",
            "\n",
            "--2024-08-21 18:22:58--  http://pifuhd.pt/\n",
            "Resolving pifuhd.pt (pifuhd.pt)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘pifuhd.pt’\n",
            "FINISHED --2024-08-21 18:22:58--\n",
            "Total wall clock time: 14s\n",
            "Downloaded: 1 files, 1.4G in 14s (109 MB/s)\n"
          ]
        }
      ],
      "source": [
        "!sh ./scripts/download_trained_model.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6heKcA-0QEBw"
      },
      "source": [
        "### Run: get new mesh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5995t2PnQTmG",
        "outputId": "8cd2d062-9f86-4289-96dd-132603bb2ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resuming from  ./checkpoints/pifuhd.pt\n",
            "Warning: opt is overwritten.\n",
            "test data size:  1\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "generate mesh (test) ...\n",
            "  0% 0/1 [00:00<?, ?it/s]./results/pifuhd_final/recon/result_B0029_rembg_256.obj\n",
            "100% 1/1 [00:05<00:00,  5.96s/it]\n"
          ]
        }
      ],
      "source": [
        "# 256 is the maximum resolution that can fit into Google Colab\n",
        "!python -m apps.simple_test -r 256 --use_rect -i $image_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acYhQc5b0H2u"
      },
      "source": [
        "### Save results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "giHQskdT0Gwa",
        "outputId": "db7f84ec-37fd-4576-c46e-52137d0c88b8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/body2vec/Bahia/dataset/fotos/3D_results_bahia/B0029_rembg'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_path = ''\n",
        "folder_name = file_name.split(\".\")[0]\n",
        "\n",
        "save_results_path = '/%s' % folder_name\n",
        "\n",
        "shutil.copytree(results_path, save_results_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eo9hFWVk0mb"
      },
      "source": [
        "### Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "326zlMLjch7N"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "#files.download('')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
